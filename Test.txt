



Given you have temperature data from two sensors, calculate the average temperature for each one second duration across both sensors.
       Constraints
Data from both sensors would not be sent at the same time.
The duration of the average should be configurable.
Assume input is in this format (Comma Separated Values)
Sensor Id,Timestamp in milliseconds from Epoch, Temperature
Example:
Input Data
1,10000,40
1,10002,45
1,11015,50
2,10005,42
2,11051,45
2,12064,42
2,13161,42

Output Data (if configuration is 1 second)
10000-10999: 42.33
11000-11999: 47.5
12000-12999: 42
13000-13999: 42
Solution:


import csv
import os

CSV_FILE_PATH = ""
avg_time = os.environ.get("TIME_DELTA", 1000)


def read_cvs_data(file_path):
    with open(file_path) as data_file:
        csvreader = csv.reader(data_file)
        rows = [row for row in csvreader]
    return rows


def calculate_avg(input_data):
    avg_dict = {}
    for data_row in input_data:
        key = int(int((data_row[1]))/avg_time)
        if key in avg_dict:
            avg_dict[key]["temp_sum"] += int(data_row[2])
            avg_dict[key]["count"] += 1
        else:
            avg_dict[key] = {"temp_sum": int(data_row[2]),"count": 1}
    for key, val in avg_dict.items():
        avg_temp = float(val["temp_sum"])/float(val["count"])
        print("{0}-{1}: {2:.2f}".format(key*avg_time, (key+1)*avg_time
- 1, avg_temp))

if __name__ == "__main__":
    data = read_cvs_data(CSV_FILE_PATH)
    calculate_avg(data)